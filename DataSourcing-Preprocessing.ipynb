{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef92bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9e8cdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ID  Year 1  Year 2  Year 3\n",
      "0  A      50      55      60\n",
      "1  B      40      42      45 \n",
      "\n",
      "  ID    Year  Value\n",
      "0  A  Year 1     50\n",
      "1  B  Year 1     40\n",
      "2  A  Year 2     55\n",
      "3  B  Year 2     42\n",
      "4  A  Year 3     60\n",
      "5  B  Year 3     45\n"
     ]
    }
   ],
   "source": [
    "data_wide = {\n",
    "    'ID': ['A', 'B'],\n",
    "    'Year 1': [50, 40],\n",
    "    'Year 2': [55, 42],\n",
    "    'Year 3': [60, 45]\n",
    "}\n",
    "\n",
    "df_wide = pd.DataFrame(data_wide)\n",
    "print(df_wide, \"\\n\")\n",
    "\n",
    "df_long = pd.melt(df_wide, id_vars = ['ID'], var_name = 'Year', value_name = 'Value')\n",
    "print(df_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4751aa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year  Year 1  Year 2  Year 3\n",
      "ID                          \n",
      "A         50      55      60\n",
      "B         40      42      45 \n",
      "\n",
      "    Year 1  Year 2  Year 3\n",
      "ID                        \n",
      "A       50      55      60\n",
      "B       40      42      45\n"
     ]
    }
   ],
   "source": [
    "df_wide2 = df_long.pivot(index = 'ID', columns = 'Year', values = 'Value')\n",
    "print(df_wide2, \"\\n\")\n",
    "df_wide2.columns = [col.replace('Year', 'Year') for col in df_wide2.columns]\n",
    "print(df_wide2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d78a72e",
   "metadata": {},
   "source": [
    "Reading and Writing DataFrames to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8ba2a630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
       "      <td>731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
       "      <td>731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
       "      <td>731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
       "      <td>731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
       "      <td>731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://mashable.com/2013/01/07/beewi-smart-toys/</td>\n",
       "      <td>731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>http://mashable.com/2013/01/07/bodymedia-armba...</td>\n",
       "      <td>731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http://mashable.com/2013/01/07/canon-poweshot-n/</td>\n",
       "      <td>731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>http://mashable.com/2013/01/07/car-of-the-futu...</td>\n",
       "      <td>731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>http://mashable.com/2013/01/07/chuck-hagel-web...</td>\n",
       "      <td>731.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url   timedelta\n",
       "0  http://mashable.com/2013/01/07/amazon-instant-...       731.0\n",
       "1  http://mashable.com/2013/01/07/ap-samsung-spon...       731.0\n",
       "2  http://mashable.com/2013/01/07/apple-40-billio...       731.0\n",
       "3  http://mashable.com/2013/01/07/astronaut-notre...       731.0\n",
       "4   http://mashable.com/2013/01/07/att-u-verse-apps/       731.0\n",
       "5   http://mashable.com/2013/01/07/beewi-smart-toys/       731.0\n",
       "6  http://mashable.com/2013/01/07/bodymedia-armba...       731.0\n",
       "7   http://mashable.com/2013/01/07/canon-poweshot-n/       731.0\n",
       "8  http://mashable.com/2013/01/07/car-of-the-futu...       731.0\n",
       "9  http://mashable.com/2013/01/07/chuck-hagel-web...       731.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_path = \"C2M1-Datasets/popularity.csv\"\n",
    "#df_csv = pd.read_csv(csv_file_path)\n",
    "df_csv = pd.read_csv(csv_file_path, \n",
    "                     sep=',', \n",
    "                     header=0, \n",
    "                     na_values=['NA','N/A', '--'], \n",
    "                     #usecols=[\"url\",\"timedelta\"],\n",
    "                     usecols=[0,1],  \n",
    "                     dtype = {'url':str}, \n",
    "                     nrows = 10,\n",
    "                    )\n",
    "df_csv.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ee54a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Transaction_ID': [101, 102, 103, 104, 105],\n",
    "    'Customer_Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Product': ['Laptop', 'Phone', 'Tablet', 'Headphones', 'Monitor'],\n",
    "    'Amount': [1200, 800, 450, 200, 300],\n",
    "    'Date': ['2025-06-01', '2025-06-02', '2025-06-03', '2025-06-04', '2025-06-05']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('transaction_data.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5a107140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 19 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   customerid  45211 non-null  int64  \n",
      " 1   age         45191 non-null  float64\n",
      " 2   salary      45211 non-null  int64  \n",
      " 3   balance     45211 non-null  int64  \n",
      " 4   marital     45211 non-null  object \n",
      " 5   jobedu      45211 non-null  object \n",
      " 6   targeted    45211 non-null  object \n",
      " 7   default     45211 non-null  object \n",
      " 8   housing     45211 non-null  object \n",
      " 9   loan        45211 non-null  object \n",
      " 10  contact     45211 non-null  object \n",
      " 11  day         45211 non-null  int64  \n",
      " 12  month       45161 non-null  object \n",
      " 13  duration    45211 non-null  object \n",
      " 14  campaign    45211 non-null  int64  \n",
      " 15  pdays       45211 non-null  int64  \n",
      " 16  previous    45211 non-null  int64  \n",
      " 17  poutcome    45211 non-null  object \n",
      " 18  response    45181 non-null  object \n",
      "dtypes: float64(1), int64(7), object(11)\n",
      "memory usage: 6.6+ MB\n"
     ]
    },
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIntCastingNaNError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m df.info()\n\u001b[32m      4\u001b[39m df.fillna(\u001b[32m0\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mage\u001b[39m\u001b[33m\"\u001b[39m]= \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m df.age.mean()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\generic.py:6665\u001b[39m, in \u001b[36mNDFrame.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m   6659\u001b[39m     results = [\n\u001b[32m   6660\u001b[39m         ser.astype(dtype, copy=copy, errors=errors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items()\n\u001b[32m   6661\u001b[39m     ]\n\u001b[32m   6663\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6664\u001b[39m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6665\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6666\u001b[39m     res = \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes)\n\u001b[32m   6667\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mastype\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\internals\\managers.py:449\u001b[39m, in \u001b[36mBaseBlockManager.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[32m    447\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mastype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\internals\\blocks.py:784\u001b[39m, in \u001b[36mBlock.astype\u001b[39m\u001b[34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[39m\n\u001b[32m    781\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan not squeeze with more than one column.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    782\u001b[39m     values = values[\u001b[32m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m new_values = \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    786\u001b[39m new_values = maybe_coerce_values(new_values)\n\u001b[32m    788\u001b[39m refs = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[39m, in \u001b[36mastype_array_safe\u001b[39m\u001b[34m(values, dtype, copy, errors)\u001b[39m\n\u001b[32m    234\u001b[39m     dtype = dtype.numpy_dtype\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     new_values = \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[39m, in \u001b[36mastype_array\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    179\u001b[39m     values = values.astype(dtype, copy=copy)\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     values = \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np.dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values.dtype.type, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\dtypes\\astype.py:101\u001b[39m, in \u001b[36m_astype_nansafe\u001b[39m\u001b[34m(arr, dtype, copy, skipna)\u001b[39m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.ensure_string_array(\n\u001b[32m     97\u001b[39m         arr, skipna=skipna, convert_na_value=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     98\u001b[39m     ).reshape(shape)\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m np.issubdtype(arr.dtype, np.floating) \u001b[38;5;129;01mand\u001b[39;00m dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33miu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_astype_float_to_int_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m arr.dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m    104\u001b[39m     \u001b[38;5;66;03m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[32m    105\u001b[39m     \u001b[38;5;66;03m# then coerce to datetime64[ns] and use DatetimeArray.astype\u001b[39;00m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m lib.is_np_dtype(dtype, \u001b[33m\"\u001b[39m\u001b[33mM\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\dtypes\\astype.py:145\u001b[39m, in \u001b[36m_astype_float_to_int_nansafe\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[33;03mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isfinite(values).all():\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m IntCastingNaNError(\n\u001b[32m    146\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    147\u001b[39m     )\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype.kind == \u001b[33m\"\u001b[39m\u001b[33mu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    149\u001b[39m     \u001b[38;5;66;03m# GH#45151\u001b[39;00m\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (values >= \u001b[32m0\u001b[39m).all():\n",
      "\u001b[31mIntCastingNaNError\u001b[39m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Bank Dataset/bank_marketing_updated_v1.csv\", skiprows=2, na_values=['NA','inf'])\n",
    "#print(df.head())\n",
    "df.info()\n",
    "df.fillna(0)\n",
    "df[\"age\"]= df[\"age\"].astype(int)\n",
    "df.age.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828df1b4",
   "metadata": {},
   "source": [
    "Reading and Writing DataFrames to Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db0c8bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name   Department  Salary\n",
      "0  Alice           HR   50000\n",
      "1    Bob  Engineering   65000\n",
      "2  Carol    Marketing   55000\n"
     ]
    }
   ],
   "source": [
    "with open('employees.txt', 'w') as f:\n",
    "    f.write(\"Name\\tDepartment\\tSalary\\n\")\n",
    "    f.write(\"Alice\\tHR\\t50000\\n\")\n",
    "    f.write(\"Bob\\tEngineering\\t65000\\n\")\n",
    "    f.write(\"Carol\\tMarketing\\t55000\\n\")\n",
    "\n",
    "df = pd.read_table(\"employees.txt\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58e3c2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>30</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>25</td>\n",
       "      <td>London</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>35</td>\n",
       "      <td>Paris</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age      City  Unnamed: 3\n",
       "0    Alice   30  New York         NaN\n",
       "1      Bob   25    London         NaN\n",
       "2  Charlie   35     Paris         NaN"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('C2M1-Datasets/Text File 2.txt')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18f5406d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name     Age City     \n",
      "Alice    30  New York \n",
      "Bob      25  London   \n",
      "Charlie  35  Paris    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('C2M1-Datasets/Text File 3.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5b62792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>30</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>25</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>35</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age      City\n",
       "0    Alice   30  New York\n",
       "1      Bob   25    London\n",
       "2  Charlie   35     Paris"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_fwf('C2M1-Datasets/Text File 3.txt')  # for fixed-width files\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd1cd8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name,Age,City\n",
      "Alice,30,New York\n",
      "Bob,25,London\n",
      "Charlie,35,Paris\n",
      "['Name,Age,City\\n', 'Alice,30,New York\\n', 'Bob,25,London\\n', 'Charlie,35,Paris']\n"
     ]
    }
   ],
   "source": [
    "# Example TXT read\n",
    "txt_file_path = 'C2M1-Datasets/Text File 1.txt'  # Replace with your TXT file path\n",
    "with open(txt_file_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "print(text[:300])  # print first 300 characters\n",
    "\n",
    "with open(txt_file_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "print(lines[:5])  # print first 5 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d106591",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'Transaction_ID': [101, 102, 103, 104, 105],\n",
    "    'Customer_Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Product': ['Laptop', 'Phone', 'Tablet', 'Headphones', 'Monitor'],\n",
    "    'Amount': [1200, 800, 450, 200, 300],\n",
    "    'Date': ['2025-06-01', '2025-06-02', '2025-06-03', '2025-06-04', '2025-06-05']\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df\n",
    "\n",
    "# Writing the DataFrame to a CSV file (which is a type of text file)\n",
    "df.to_csv('output.txt', sep='\\t', index=False)  # Tab-separated file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eeb713",
   "metadata": {},
   "source": [
    "Reading and Writing DataFrames to Excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "928bc51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>West</td>\n",
       "      <td>4.56000</td>\n",
       "      <td>13.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>West</td>\n",
       "      <td>4390.36650</td>\n",
       "      <td>6362.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>East</td>\n",
       "      <td>-53.80960</td>\n",
       "      <td>211.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Central</td>\n",
       "      <td>803.47050</td>\n",
       "      <td>1164.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Central</td>\n",
       "      <td>-24.03000</td>\n",
       "      <td>22.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>South</td>\n",
       "      <td>280.27458</td>\n",
       "      <td>130.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>South</td>\n",
       "      <td>-112.42630</td>\n",
       "      <td>6945.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>South</td>\n",
       "      <td>24.92400</td>\n",
       "      <td>30.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>East</td>\n",
       "      <td>-2.90950</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>West</td>\n",
       "      <td>-76.89000</td>\n",
       "      <td>901.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Region      Profit    Sales\n",
       "0      West     4.56000    13.01\n",
       "1      West  4390.36650  6362.85\n",
       "2      East   -53.80960   211.15\n",
       "3   Central   803.47050  1164.45\n",
       "4   Central   -24.03000    22.23\n",
       "..      ...         ...      ...\n",
       "95    South   280.27458   130.62\n",
       "96    South  -112.42630  6945.16\n",
       "97    South    24.92400    30.94\n",
       "98     East    -2.90950     3.42\n",
       "99     West   -76.89000   901.81\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel( \"C2M1-Datasets/SuperStoreUS-2015.xlsx\",\n",
    "                   sheet_name=\"Orders\",\n",
    "                   usecols=[\"Region\",\"Sales\",\"Profit\"],\n",
    "                   skiprows=0,\n",
    "                   nrows=100,\n",
    "                   dtype={\"Region\":str,\"Sales\":float},\n",
    "                   na_values=[\"NA\", \"missing\"]\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a42b06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Transaction_ID Customer_Name     Product  Amount        Date\n",
      "0             101         Alice      Laptop    1200  2025-06-01\n",
      "1             102           Bob       Phone     800  2025-06-02\n",
      "2             103       Charlie      Tablet     450  2025-06-03\n",
      "3             104         David  Headphones     200  2025-06-04\n",
      "4             105           Eve     Monitor     300  2025-06-05\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Transaction_ID': [101, 102, 103, 104, 105],\n",
    "    'Customer_Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Product': ['Laptop', 'Phone', 'Tablet', 'Headphones', 'Monitor'],\n",
    "    'Amount': [1200, 800, 450, 200, 300],\n",
    "    'Date': ['2025-06-01', '2025-06-02', '2025-06-03', '2025-06-04', '2025-06-05']\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n",
    "excelpath = \"transaction1.xlsx\"\n",
    "df.to_excel( excelpath,\n",
    "             sheet_name=\"df_data\",\n",
    "             index=False,\n",
    "             header=True,\n",
    "             startrow=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f6d1ba",
   "metadata": {},
   "source": [
    "Reading and Writing DataFrames to JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4425c16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>None</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500  None        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250  None        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500  None        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000  None        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500  None        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500  None        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\n",
    "    path_or_buf=\"C2M1-Datasets/titanic.json\",  # Path to the JSON file\n",
    "    orient=None,                 # Infers the structure format (used when not JSON Lines)\n",
    "    typ='frame',                 # Return a DataFrame (default is 'frame'; other option is 'series')\n",
    "    dtype=True,                  # Let pandas infer column data types\n",
    "    convert_axes=True,           # Convert axes to proper types (e.g., numeric index)\n",
    "    convert_dates=True,          # Automatically convert date strings to datetime\n",
    "    keep_default_dates=True,     # Also parse pandas-specific date formats\n",
    "    precise_float=False,         # Set to True for higher precision in floating point numbers\n",
    "    date_unit='ms',              # Use when converting numeric dates (ignored here, but good to know)\n",
    "    encoding='utf-8',            # Encoding used to decode the file\n",
    "    lines=True                   # Required for JSON Lines format (NDJSON)\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d144fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Transaction_ID Customer_Name     Product  Amount        Date\n",
      "0             101         Alice      Laptop    1200  2025-06-01\n",
      "1             102           Bob       Phone     800  2025-06-02\n",
      "2             103       Charlie      Tablet     450  2025-06-03\n",
      "3             104         David  Headphones     200  2025-06-04\n",
      "4             105           Eve     Monitor     300  2025-06-05\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Transaction_ID': [101, 102, 103, 104, 105],\n",
    "    'Customer_Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Product': ['Laptop', 'Phone', 'Tablet', 'Headphones', 'Monitor'],\n",
    "    'Amount': [1200, 800, 450, 200, 300],\n",
    "    'Date': ['2025-06-01', '2025-06-02', '2025-06-03', '2025-06-04', '2025-06-05']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "df.to_json(\"transaction_data1.json\", orient=\"records\", lines=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10d4cd7",
   "metadata": {},
   "source": [
    "Read and write to SQL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fca41869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id     name  age\n",
      "0   1    Alice   30\n",
      "1   2      Bob   25\n",
      "2   3  Charlie   35\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "with open('C2M1-Datasets/Create database.sql', 'r') as f:\n",
    "    sql_script = f.read()\n",
    "\n",
    "conn = sqlite3.connect(':memory:')\n",
    "\n",
    "conn.executescript(sql_script)\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM users\", conn)\n",
    "\n",
    "print(df)\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bcbb20cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name  value\n",
      "id                \n",
      "1     Alice   23.5\n",
      "2       Bob   45.2\n",
      "3   Charlie   31.8\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(':memory:')\n",
    "conn.execute(\"CREATE TABLE sample_table (id INTEGER PRIMARY KEY, name TEXT, value REAL)\")\n",
    "conn.execute(\"INSERT INTO sample_table (name, value) VALUES ('Alice', 23.5), ('Bob', 45.2), ('Charlie', 31.8)\")\n",
    "\n",
    "sql_query = 'SELECT * FROM sample_table'\n",
    "df = pd.read_sql_query(sql=sql_query, con=conn, index_col='id')\n",
    "\n",
    "print(df)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4bd99d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Transaction_ID': [101, 102, 103, 104, 105],\n",
    "    'Customer_Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Product': ['Laptop', 'Phone', 'Tablet', 'Headphones', 'Monitor'],\n",
    "    'Amount': [1200, 800, 450, 200, 300],\n",
    "    'Date': ['2025-06-01', '2025-06-02', '2025-06-03', '2025-06-04', '2025-06-05']\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "with open('transaction_data.sql', 'w') as file:\n",
    "    # Write the CREATE TABLE statement\n",
    "    file.write(\"CREATE TABLE IF NOT EXISTS transactions (\\n\")\n",
    "    file.write(\"    Transaction_ID INTEGER PRIMARY KEY,\\n\")\n",
    "    file.write(\"    Customer_Name TEXT,\\n\")\n",
    "    file.write(\"    Product TEXT,\\n\")\n",
    "    file.write(\"    Amount INTEGER,\\n\")\n",
    "    file.write(\"    Date TEXT\\n\")\n",
    "    file.write(\");\\n\\n\")\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        file.write(f\"INSERT INTO transactions (Transaction_ID, Customer_Name, Product, Amount, Date) VALUES ({row['Transaction_ID']}, '{row['Customer_Name']}', '{row['Product']}', {row['Amount']}, '{row['Date']}');\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23e369d",
   "metadata": {},
   "source": [
    "Reading HTML tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a2a7add9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3667458138.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpip install lxml\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install lxml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3dc961fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Installing collected packages: urllib3, idna, charset_normalizer, certifi, requests\n",
      "\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   ---------------- ----------------------- 2/5 [charset_normalizer]\n",
      "   ---------------------------------------- 5/5 [requests]\n",
      "\n",
      "Successfully installed certifi-2025.10.5 charset_normalizer-3.4.4 idna-3.11 requests-2.32.5 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d89edd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'C:\\Users\\Dhivya' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b8fa90e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "84de5d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 tables on the page.\n",
      "                 Title     Release date           Genre     Runtime Language\n",
      "0  Society of the Snow  January 4, 2024  Disaster drama  2 h 25 min  Spanish\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 137 entries, 0 to 136\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   Film_Title    137 non-null    object        \n",
      " 1   Release_Date  137 non-null    datetime64[ns]\n",
      " 2   Genre         137 non-null    object        \n",
      " 3   Runtime       137 non-null    object        \n",
      " 4   Language      137 non-null    object        \n",
      "dtypes: datetime64[ns](1), object(4)\n",
      "memory usage: 5.5+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhivya Karthikeyan\\AppData\\Local\\Temp\\ipykernel_21260\\291233833.py:8: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(response.text)\n"
     ]
    }
   ],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_Netflix_original_films_(2024)\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "tables = pd.read_html(response.text)\n",
    "\n",
    "print(f\"Found {len(tables)} tables on the page.\")\n",
    "\n",
    "df = tables[0]\n",
    "print(df.head(1))\n",
    "df.columns\n",
    "\n",
    "df = df.rename(columns={\n",
    "    'Title': 'Film_Title',\n",
    "    'Release date': 'Release_Date',\n",
    "    'Genre(s)': 'Genres',\n",
    "    'Director(s)': 'Directors',\n",
    "    # Add more renames based on actual header names\n",
    "})\n",
    "\n",
    "df['Release_Date'] = pd.to_datetime(df['Release_Date'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# 🎉 Final: `df` now holds the Netflix films list in a tidy, pandas-ready format\n",
    "print(df.info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
