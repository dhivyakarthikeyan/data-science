{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries (do not edit)\n",
    "from ast import literal_eval\n",
    "\n",
    "# Function to identify invalid email ID\n",
    "def identify_invalid_email(record):\n",
    "    # email = record.get('Email ID')\n",
    "    email = record['Email ID']\n",
    "\n",
    "     # Email ID can't be blank\n",
    "    if len(email) == 0:\n",
    "        record['Email ID'] = 'invalid'\n",
    "        return record\n",
    "\n",
    "    # Must contain '@' and '.'\n",
    "    if '@' not in email or '.' not in email:\n",
    "        record['Email ID'] = 'invalid'\n",
    "        return record\n",
    "\n",
    "    # '.' must come after '@' with at least one character in between\n",
    "    at_index = email.find('@')\n",
    "    dot_index = email.find('.')\n",
    "    index_diff = dot_index - at_index\n",
    "    if index_diff <= 1: record['Email ID'] = 'invalid'\n",
    "    \n",
    "    return record\n",
    "\n",
    "# Inpout and output processing  (do not edit)\n",
    "print(identify_invalid_email(literal_eval(input())))\n",
    "\n",
    "\n",
    "#inputs:\n",
    "'''\n",
    "{'Candidate Name': 'Nikhil', 'Email ID': 'nikhil98singhdomain.com'}\n",
    "{'Candidate Name': 'Dravid', 'Email ID': 'dravidlee@domaincom'}\n",
    "{'Candidate Name': 'Rashid', 'Email ID': 'rashid.khan@domaincom'}\n",
    "{'Candidate Name': 'Maggie', 'Email ID': '7777@domain.com'}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f78cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file (do not edit)\n",
    "import pandas as pd\n",
    "df = pd.read_csv('https://d3ejq4mxgimsmf.cloudfront.net/AirPassengers-1eaa575774ad408691e22a1edfcab2ec.csv')\n",
    "\n",
    "# Convert the 'Month' column to datetime format and extract the year from the 'Month' column\n",
    "df['Year'] = pd.to_datetime(df['Month']).dt.year\n",
    "\n",
    "# Group by year and calculate the mean passenger count\n",
    "mean_passengers_by_year = df.groupby('Year')['Passengers'].mean()\n",
    "\n",
    "# Input and output processing (do not edit)\n",
    "mean_passengers_by_year = mean_passengers_by_year.round(0).astype(int)\n",
    "print(mean_passengers_by_year.loc[int(input())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1616343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file using Pandas (do not edit)\n",
    "import pandas as pd\n",
    "df = pd.read_csv('https://d3ejq4mxgimsmf.cloudfront.net/active_grandmasters_March25-b0e7a64fd25c48ab8f380debb40e8a0a.csv')\n",
    "\n",
    "# Calculate the mean rating for each federation\n",
    "federation_mean_stats = df.groupby('Fed')['Rating'].mean().reset_index()\n",
    "\n",
    "# Add the list of players above the mean rating for each federation\n",
    "federation_mean_stats['Players Above Mean'] = federation_mean_stats['Fed'].apply(\n",
    "    lambda federation: df[(df['Fed'] == federation) & (df['Rating'] >= federation_mean_stats.loc[federation_mean_stats['Fed'] == federation, 'Rating'].values[0])]['Name'].tolist()\n",
    ")\n",
    "\n",
    "# Set the federation as the index\n",
    "federation_mean_stats = federation_mean_stats.set_index('Fed')\n",
    "players_above_mean = federation_mean_stats['Players Above Mean']\n",
    "\n",
    "# Input and output processing (do not edit)\n",
    "print(players_above_mean.loc[input()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bde675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_data = input()\n",
    "product_category, start_date, end_date = map(str.strip, input_data.split(','))\n",
    "\n",
    "def aggregate_monthly_sales(input_tuple, filename='https://d3ejq4mxgimsmf.cloudfront.net/Product_sales_data-9f83ae7a11c340d1884ae214aadbacac.csv'):\n",
    "    # Unpack the input tuple\n",
    "    product_category, start_date, end_date = input_tuple\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Convert sale_date to datetime\n",
    "    df['sale_date'] = pd.to_datetime(df['sale_date'])\n",
    "\n",
    "    # Convert input dates to datetime\n",
    "    start = pd.to_datetime(start_date)\n",
    "    end = pd.to_datetime(end_date)\n",
    "\n",
    "    # Filter by product category and date range\n",
    "    filtered_df = df[\n",
    "        (df['product_category'] == product_category) &\n",
    "        (df['sale_date'] >= start) &\n",
    "        (df['sale_date'] <= end)\n",
    "    ].copy()\n",
    "\n",
    "    # Check if the date range spans more than one month\n",
    "    if start.month != end.month:\n",
    "        # Aggregate monthly\n",
    "        filtered_df['month'] = filtered_df['sale_date'].dt.to_period('M').astype(str)\n",
    "        result = filtered_df.groupby('month')['sales_amount'].sum().reset_index()\n",
    "        return list(result.itertuples(index=False, name=None))\n",
    "    else:\n",
    "        # Aggregate daily\n",
    "        filtered_df.loc[:, 'day'] = filtered_df['sale_date'].dt.to_period('D').astype(str)\n",
    "        result = filtered_df.groupby('day')['sales_amount'].sum().reset_index()\n",
    "        return list(result.itertuples(index=False, name=None))\n",
    "\n",
    "output = aggregate_monthly_sales((product_category, start_date, end_date))\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef61ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data (do not edit)\n",
    "import pandas as pd\n",
    "filename = 'https://d3ejq4mxgimsmf.cloudfront.net/hourly_energy_usage-9eb4bd3748964f8da8d95b54df732b1d.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "def analyze_household_peak_usage(household_id):\n",
    "    # Define the segments and their corresponding hour indices\n",
    "    segments = {\n",
    "        'Late Night/Early Morning': list(range(0, 6)),\n",
    "        'Morning': list(range(6, 12)),\n",
    "        'Afternoon': list(range(12, 18)),\n",
    "        'Evening/Night': list(range(18, 24))\n",
    "    }\n",
    "\n",
    "    # Filter the row for the specified household\n",
    "    household_data = df[df['Household_ID'] == household_id]\n",
    "\n",
    "    # Extract hourly values\n",
    "    hourly_values = household_data.iloc[0, 1:].values  # Skip Household_ID column\n",
    "\n",
    "    # Calculate average consumption for each segment\n",
    "    segment_averages = {}\n",
    "    for segment_name, indices in segments.items():\n",
    "        segment_values = [hourly_values[i] for i in indices]  # The indices here accurately match the hour columns\n",
    "        segment_avg = sum(segment_values) / len(segment_values)\n",
    "        segment_averages[segment_name] = segment_avg\n",
    "\n",
    "    # Identify the segment with the highest average consumption\n",
    "    peak_segment = max(segment_averages, key = segment_averages.get)\n",
    "    peak_indices = segments[peak_segment]\n",
    "    peak_avg = segment_averages[peak_segment]\n",
    "\n",
    "    # Find hours in the peak segment where consumption is above the segment average\n",
    "    high_usage_hours = [i for i in peak_indices if hourly_values[i] > peak_avg]\n",
    "\n",
    "    # Return the result as a dictionary\n",
    "    return {'Peak Segment': peak_segment, 'High Usage Hours': high_usage_hours}\n",
    "\n",
    "# Input and output processing (do not edit)\n",
    "print(analyze_household_peak_usage(input()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
